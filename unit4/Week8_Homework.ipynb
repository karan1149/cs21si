{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week8_Homework.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lye5s9CPypf",
        "colab_type": "text"
      },
      "source": [
        "# Week 8 Homework: Classification of Google Street View Images\n",
        "\n",
        "As Timnit talked about in her guest lecture, \"socioeconomic attributes such as income, race, education, and voting patterns can be inferred from cars detected in Google Street View images using deep learning.\" This week, we'll be working on classifying car makes that appear in Google Street View images to produce this kind of visual census data.\n",
        "\n",
        "Check out Timnit's paper [here](https://www.pnas.org/content/114/50/13108) and you can find our data [here](https://ai.stanford.edu/~tgebru/car_data.html).\n",
        "\n",
        "Before you run the below cell, be sure to make sure that you are using GPU (Edit->Notebook settings) because we will be training larger networks than before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO9X465UXEOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras import optimizers\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd21_w8318vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download annotations\n",
        "r = requests.get(\"http://web.stanford.edu/class/cs21si/resources/timnit_resources.zip\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSMfNiSa7gjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download images\n",
        "r = requests.get(\"https://www.dropbox.com/s/uxmng8gu1bg1dcz/unit4_week8_resources.zip?dl=1\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nJ-fXMv3VJN",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Clean the Data\n",
        "\n",
        "Here we'll be taking a subset of our dataset and cleaning it by removing unused columns and unlabeled examples. This is for the purposes of visualization in Part 2. Behind the scenes, the teaching team has used similar code to clean the entire dataset. Read through the code to understand what it is doing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPAKquL3UpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in training data\n",
        "train_data = pd.read_csv('annotations/gsv_annos/gsv_train.txt', \n",
        "                         names = ['fname', 'bbox', 'group', 'class', 'big_enough', 'image_id'])\n",
        "\n",
        "# drop unused columns\n",
        "filtered_train_data = train_data.drop('class', axis = 1)\n",
        "filtered_train_data = filtered_train_data.drop('big_enough', axis = 1)\n",
        "\n",
        "# filter training data without class labels\n",
        "filtered_train_data = filtered_train_data[filtered_train_data['group'] != -1]\n",
        "\n",
        "filtered_train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nuvpxh13ofG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in annotations about car model and make\n",
        "class_data = pd.read_csv('annotations/attribute_annos/group_id_car_atts.txt')\n",
        "class_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3bnMkvz4Ucn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map group ID to car make\n",
        "filtered_train_data['make'] = ''\n",
        "\n",
        "for index, row in filtered_train_data.iterrows():\n",
        "    group = row['group']\n",
        "    make = class_data[class_data['group_id'] == int(group)]['make'].values\n",
        "    filtered_train_data.at[index, 'make'] = make[0] \n",
        "    \n",
        "filtered_train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyCOpmGO4WY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove entries with an uncommon make (fewer than 100)\n",
        "uncommon_makes = filtered_train_data['make'].value_counts()[-19:].index\n",
        "filtered_train_data = filtered_train_data.loc[~filtered_train_data['make'].isin(uncommon_makes)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi1w0U2x2zsG",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Visualize the Data\n",
        "\n",
        "Just as in previous assignments, we begin by looking to better understand our data. Here, your job is to use the function *visualize_train_image* below to display images. You can find image file names in `filtered_train_data` above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f60RLO2l2e4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_url_from_fname(fname):\n",
        "    base_url = 'http://imagenet.stanford.edu/geo/gsv_100k_unwarp'\n",
        "    return os.path.join(base_url, fname)\n",
        "\n",
        "def get_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    return np.array(Image.open(BytesIO(response.content)), dtype=np.uint8)\n",
        "\n",
        "def visualize_train_image(fname, bbox = True):\n",
        "    url = make_url_from_fname(fname)\n",
        "    im = get_image_from_url(url)\n",
        "    plt.imshow(im)\n",
        "    \n",
        "    if bbox:\n",
        "        entry = filtered_train_data.loc[filtered_train_data['fname'] == fname].iloc[0]        \n",
        "        bbox = entry['bbox'].split()\n",
        "        x1, y1, x2, y2 = [int(i) for i in bbox]\n",
        "        rect = Rectangle((x1, y1), (x2 - x1), (y2 - y1), linewidth = 2, \n",
        "                         edgecolor = 'r', facecolor = 'none')\n",
        "        plt.gca().add_patch(rect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCE_vwmS2zIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "\n",
        "### END YOUR CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC1D0w356D6A",
        "colab_type": "text"
      },
      "source": [
        "## Part 3: Exploring CNN Architectures \n",
        "\n",
        "At this point in the course, you've had the opportunity to construct and train your own convolutional neural networks with extra bells and whistles like pooling or batch normalization layers. Your CNNs were likely only a few layers deep, which constrains the representative power of the models. \n",
        "\n",
        "Thankfully, researchers around the world have been working on stacking more and more layers to create deeper architectures. However, early on, these researchers found that deeper networks actually performed worse. Why could this be?\n",
        "\n",
        "The authors of an architecture called [ResNet](https://arxiv.org/abs/1512.03385) observed something simple: direct mappings are hard to learn. Instead of trying to learn an underlying mapping from $x$ to $f(x)$, we can learn the difference between the two, or the “residual.” Then, to calculate $f(x)$, we can just add the residual to the input. Say the residual is $r(x) = f(x) - x$. Now, instead of trying to learn $f(x)$ directly, our networks are trying to learn $r(x)+x$. You can check out this [blog post](https://towardsdatascience.com/an-intuitive-guide-to-deep-network-architectures-65fdc477db41) to learn more.\n",
        "\n",
        "We'll be exploring a 50-layer ResNet CNN architecture in Keras in Part 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiITuMs6BRpi",
        "colab_type": "text"
      },
      "source": [
        "Before we jump into training our ResNet though, we need to load our data in with Keras data generators. Data generators are cool because they quickly iterate through your sets in batches. The batch size is a hyperparameter you can tune. We've put together that code for you. You can go ahead and play around with the batch size later when submitting your final model (note that batch sizes above 64 might cause memory errors, because very large batches will not fit on GPU)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM91JFk5MXtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "batch_size = 32 \n",
        "### END YOUR CODE ###\n",
        "\n",
        "def get_data_generator(set_name, batch_size):\n",
        "    datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip = set_name == 'train')\n",
        "    generator = datagen.flow_from_directory('data/' + set_name,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = 'categorical')\n",
        "    return generator\n",
        "    \n",
        "train_generator = get_data_generator('train', batch_size)\n",
        "val_generator = get_data_generator('val', batch_size)\n",
        "test_generator = get_data_generator('test', batch_size)\n",
        "\n",
        "num_classes = 31"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzEhoBN5Cp76",
        "colab_type": "text"
      },
      "source": [
        "We can see that there are 31 classes and input images are 224x224 with 3 color channels (RGB).\n",
        "\n",
        "Keras has an easy API for loading the ResNet-50. You can play around with the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdyMHPVPCWGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "lr = 1e-3\n",
        "### END YOUR CODE ###\n",
        "\n",
        "def get_base_resnet_model(lr):\n",
        "    model = keras.applications.ResNet50(include_top = True, weights = None, \n",
        "                                        classes = num_classes, input_shape=(224, 224, 3), \n",
        "                                        input_tensor = None)\n",
        "\n",
        "    optim = optimizers.Adam(lr = lr)\n",
        "    model.compile(optimizer = optim, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "base_resnet_model = get_base_resnet_model(lr)\n",
        "base_resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-2CsufTDQoa",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our 50-layer architecture set up, let's train it for 1 epoch (to avoid long training times)! Refer to the [documentation](https://keras.io/models/model/#fit_generator) to fit the model to the data from your generators. This will take around 10 minutes (make sure to run on GPU)! The training script will print out loss and accuracies as it trains–note that accuracies will be lower than you've seen before because we have many more output classes and we are only training for one epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkmyJjdpDXWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_resnet_model.fit_generator(train_generator,\n",
        "                                steps_per_epoch = len(train_generator),\n",
        "                                epochs = 1,\n",
        "                                validation_data = val_generator,\n",
        "                                validation_steps = len(val_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_4OvTb-ELoi",
        "colab_type": "text"
      },
      "source": [
        "## Part 4: Transfer Learning\n",
        "\n",
        "Good job training your first super-deep network! For some historical context, ResNet was created for the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). From the ImageNet [website](http://image-net.org/challenges/LSVRC/), \"ILSVRC evaluates algorithms for object detection and image classification at large scale. One high level motivation is to allow researchers to compare progress... across a wider variety of objects -- taking advantage of the quite expensive labeling effort.\" In other words, ImageNet is a huge labeled dataset that researchers can use to benchmark their architectures. \n",
        "\n",
        "After ResNet-50 is trained on ImageNet, we can save the weights and use them to bootstrap another task with the same architecture. This technique is broadly called **transfer learning**. As discussed in this [blog post](https://machinelearningmastery.com/transfer-learning-for-deep-learning/), \"In transfer learning, we first train a base network on a base dataset and task, and then we repurpose the learned features, or transfer them, to a second target network to be trained on a target dataset and task. This process will tend to work if the features are general, meaning suitable to both base and target tasks, instead of specific to the base task.\" In this case, the task is image classification on a different dataset.\n",
        "\n",
        "In Part 4, you'll have the opportunity to use a ResNet initialized with **pretrained weights** and see how it does on your task. Note that the ImageNet dataset has 1000 classes but our dataset only has 31 classes, so we'll have to replace the last layer of our ResNet to reflect that difference. Again, you can play around with the learning rate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA2_LfJiUoBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "lr = 1e-3\n",
        "### END YOUR CODE ###\n",
        "\n",
        "def get_pretrained_resnet_model(lr):\n",
        "    # here, we pass in weights = 'imagenet' instead of weights = None\n",
        "    pretrained_resnet = keras.applications.ResNet50(include_top = False, weights = 'imagenet', \n",
        "                                                    classes = num_classes, input_shape = (224, 224, 3), \n",
        "                                                    input_tensor = None)\n",
        "    # replace last layer (including the pooling)\n",
        "    h = GlobalAveragePooling2D()(pretrained_resnet.output)\n",
        "    y_hat = Dense(num_classes, activation = 'softmax', name = 'fc1000')(h)\n",
        "    \n",
        "    model = Model(input = pretrained_resnet.input, output = y_hat)\n",
        "\n",
        "    optim = optimizers.Adam(lr = lr)\n",
        "    model.compile(optimizer = optim, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "pretrained_resnet_model = get_pretrained_resnet_model(lr)\n",
        "pretrained_resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIGrGnOSHyEp",
        "colab_type": "text"
      },
      "source": [
        "Train your new pretrained model for 1 epoch. Refer to the code for *base_resnet_model* above to see how to use *fit_generator*!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQczxGLjHxf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "pretrained_resnet_model.fit_generator(None)\n",
        "### END YOUR CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd3g94-_ImMB",
        "colab_type": "text"
      },
      "source": [
        "## Part 5: Transfer Learning with Frozen Layers\n",
        "\n",
        "As you might have noticed, training these 50-layer ResNets end-to-end takes quite a bit more time than our previous smaller models. One of the big benefits of transfer learning is that it can oftentimes speed up training. \n",
        "\n",
        "In CNNs, features are more generic in early layers and more original-dataset-specific in later layers. This means that the initial layers of the ResNet model are still useful for this new task. So, we can choose to keep our ImageNet weights in earlier layers and only finetune them in later layers. We do this by freezing earlier layers and making them untrainable. We thus introduce an additional hyperparameter: the number of frozen layers. Note that due to different definitions for what a \"layer\" means, model.layers contains 177 layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjKT7k9HIly1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "lr = 1e-3\n",
        "num_freeze_layers = 30\n",
        "### END YOUR CODE ###\n",
        "\n",
        "def get_pretrained_frozen_resnet_model(lr, num_freeze_layers):\n",
        "    pretrained_resnet = keras.applications.ResNet50(include_top = False, weights = 'imagenet', \n",
        "                                                    classes = 31, input_shape = (224, 224, 3), \n",
        "                                                    input_tensor = None)\n",
        "    # replace last layer (including the pooling)\n",
        "    h = GlobalAveragePooling2D()(pretrained_resnet.output)\n",
        "    y_hat = Dense(num_classes, activation = 'softmax', name = 'fc1000')(h)\n",
        "    \n",
        "    model = Model(input = pretrained_resnet.input, output = y_hat)\n",
        "\n",
        "    optim = optimizers.Adam(lr = lr)\n",
        "    model.compile(optimizer = optim, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    print('Freezing %d of %d model layers...' % (num_freeze_layers, len(model.layers)))\n",
        "    \n",
        "    if not num_freeze_layers:\n",
        "        for layer in model.layers[:num_freeze_layers]:\n",
        "            layer.trainable = False\n",
        "        for layer in model.layers[num_freeze_layers:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    return model\n",
        "    \n",
        "pretrained_frozen_resnet_model = get_pretrained_frozen_resnet_model(lr, num_freeze_layers)\n",
        "pretrained_frozen_resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNf7loq8KehW",
        "colab_type": "text"
      },
      "source": [
        "Train your new pretrained model with frozen layers for 1 epoch. Notice that training is a bit faster now, depending on how many layers you are freezing, since we are training fewer layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIKPYkCXKeI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "pretrained_frozen_resnet_model.fit_generator(None)\n",
        "### END YOUR CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3BppKwsKoxG",
        "colab_type": "text"
      },
      "source": [
        "## Part 6: Evaluation\n",
        "\n",
        "At this point, we've trained a base 50-layer ResNet and a pretrained ResNet initialized with ImageNets weights. We've also finetuned a pretrained ResNet in Part 5. After completing hyperparameter tuning above (and also training for more epochs, if you like), pick the best of your three models according to validation performance and run evaluation on your test set. Note that you do not have to wait for training to complete to get an idea of what hyperparameters are doing well–you can keep track of how quickly the loss decreases.\n",
        "\n",
        "Remember: to avoid bias, only run evaluation on the test set once! Use validation accuracy (reported at the end of an epoch) to tune hyperparameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwzyWb9QHZWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN YOUR CODE ###\n",
        "\n",
        "# Save your best model to best_model here\n",
        "\n",
        "loss, acc = best_model.evaluate_generator(test_generator, len(test_generator))\n",
        "\n",
        "print('Your best test loss was', loss)\n",
        "print('Your best test accuracy was', acc)\n",
        "### END YOUR CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr2uDScXNJSU",
        "colab_type": "text"
      },
      "source": [
        "## And that's a wrap!\n",
        "\n",
        "The skills covered in this notebook are very critical for deep learning in practice, because machine learning engineers don't want to keep reinventing the wheel. Good work finishing up this assignment! "
      ]
    }
  ]
}