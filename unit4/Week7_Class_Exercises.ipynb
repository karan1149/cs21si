{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week7_Class_Exercises.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHV6I0fuzyom",
        "colab_type": "text"
      },
      "source": [
        "# Week 7 Exercises\n",
        "\n",
        "This week we'll be exploring computer vision & neural networks by training a convolutional neural network (CNN) on ADDI (Automated computer-based Diagnosis system for Dermascopic Images) dataset. You are able to run this notebook on GPU to speed up training and predictions, since we are building a larger model than before (in the toolbar, click Edit->Notebook settings->Hardware accelerator). Run the below cell to get started (may take a few minutes to download data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3q6XO4Szyon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Download and extract data.\n",
        "r = requests.get(\"http://web.stanford.edu/class/cs21si/resources/unit4_resources.zip\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "base_path = 'unit4_resources/addi/'\n",
        "train_path = base_path + 'train'\n",
        "val_path = base_path + 'val'\n",
        "test_path = base_path + 'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRLQbwiTzyoq",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1: Visualize the Data\n",
        "\n",
        "Check out some of the images from the dataset by running the code below! Feel free to change the indices (\"*idx*\") to look through other images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF99-BVozyor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_example(label, idx=0):\n",
        "    img_name = os.listdir('%s/%s' % (train_path, label))[idx]\n",
        "    path = '%s/%s/%s' % (train_path, label, img_name)\n",
        "    img = plt.imread(path)\n",
        "    print('Showing %s image with index %d' % (label, idx))\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "show_example('normal', idx=0), show_example('abnormal', idx=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-sUDWIzyot",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: Train a Simple CNN\n",
        "\n",
        "Now, we'll create a simple CNN model with just convolutional and fully-connected layers on the task. Much of the code is heavily influenced by [the Keras CNN tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), so definitely check that out!\n",
        "\n",
        "### Load the data\n",
        "Below, we have code that loads the data as an ImageDataGenerator, which will make it convenient for the Keras framework to deal with. Notice that the train generator has more input parameters--these are called data augmentations and allow us to generalize better when we have little training data. Read more about data augmentation [here](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced).\n",
        "\n",
        "Run the code below to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "K1Q6Rhrqzyou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(batch_size):\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_path, \n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "    val_generator = test_datagen.flow_from_directory(val_path,\n",
        "                                                            target_size=(150, 150),\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            class_mode='binary')\n",
        "    \n",
        "    test_generator = test_datagen.flow_from_directory(test_path,\n",
        "                                                      target_size=(150, 150),\n",
        "                                                      batch_size=batch_size,\n",
        "                                                      class_mode='binary')\n",
        "    \n",
        "    return train_generator, val_generator, test_generator\n",
        "\n",
        "train_generator, val_generator, test_generator = load_data(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyuDnyYPzyow",
        "colab_type": "text"
      },
      "source": [
        "### Create your Model\n",
        "\n",
        "Write the code for your simple CNN below. Check out the [Keras documentation on CNNs](https://keras.io/layers/convolutional/) for reference!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "663HXIOLzyow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_simple_cnn():\n",
        "    ### YOUR CODE HERE ###\n",
        "    model = Sequential()\n",
        "\n",
        "    \n",
        "    ### END CODE ###\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "simple_model = get_simple_cnn()\n",
        "simple_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwNZ-zc9zyoy",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model!\n",
        "\n",
        "Run the code below to train your simple model on the training data, evaluating on the validation data at every epoch. You should get around 60% on the validation set with this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBOjdVWqzyoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train_generator, validation_generator, epochs=5):\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=len(train_generator),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=len(validation_generator))\n",
        "    \n",
        "train_model(simple_model, train_generator, val_generator, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNqgbVJvzyo1",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3: Train an Advanced CNN\n",
        "\n",
        "Now, we'll create a more advanced CNN model by adding max-pooling and spatial batch-normalization.\n",
        "\n",
        "### Create your Model\n",
        "\n",
        "Architect your advanced model below. Again, be sure to reference the [Keras CNN docs](https://keras.io/layers/convolutional/), as well as the [Keras Normalization docs](https://keras.io/layers/normalization/) (for the Spatial Batch Norm layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tngL5n6zyo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_advanced_cnn():\n",
        "    ### YOUR CODE HERE ###\n",
        "    model = Sequential()\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    ### END CODE ###\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "advanced_model = get_advanced_cnn()\n",
        "advanced_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctHGtz59zyo4",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model!\n",
        "\n",
        "Run the code below to train your advanced model on the training data, evaluating on the validation data at every epoch. You should be able to get around 70% accuracy on validation with this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfA_eRltzyo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(advanced_model, train_generator, val_generator, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e3jT-Ytzyo8",
        "colab_type": "text"
      },
      "source": [
        "### Evalutate the Model\n",
        "\n",
        "Evaluate your model on the test set below! The first number is the loss, and the second is the accuracy. You should be able to get around 70% accuracy on the test set with your advanced model, but this will vary significantly due to randomness!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0TB2fJgzyo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "advanced_model.evaluate_generator(test_generator, len(test_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFFbZJ_u0IU3",
        "colab_type": "text"
      },
      "source": [
        "Great work! For homework, we'll see that our model is susceptible to adversarial attacks, images that look the same to humans but are perturbed in a very particular way in order to fool our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY2GFQRN0XU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}