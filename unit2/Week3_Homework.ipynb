{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3_Homework.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RD-xaf65gZri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Week 3 Homework: Predicting Loan Approval Using Logistic Regression\n",
        "\n",
        "In this homework, we will be training a classifier to predict whether or not someone is a good candidate for a loan using machine learning. We have access to various features about each person and whether or not they are considered to be good candidates. We will use this as training data for a simple logistic regression classifier.\n",
        "\n",
        "The topic of predicting loan eligibility using machine learning is a very touchy subject. Obviously, useful information for making the decision includes protected class attributes, such as race and gender. Remember: bias in gives bias out--data from humans often has societal bias imbued in it, so it is important that your model doesn't accidentally reflect this bias.\n",
        "\n",
        "The focus of this assignment will be seeing how we can use the same techniques/code from class for an entirely new domain. We will also examine the gender bias of our algorithm at the end of the assignment!"
      ]
    },
    {
      "metadata": {
        "id": "V21BoXxZkPJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "# Download class resources...\n",
        "r = requests.get(\"http://web.stanford.edu/class/cs21si/resources/unit2_resources.zip\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SSK6VIfD5Gpl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will be working with the German Credit Dataset. Each row represents a person, and each column gives their value for a specific feature. The features are shown at the top. The application of the resulting prediction task could be an automated way of approving loans!\n",
        "\n",
        "Run the following cell to load the data below to see a sample of the data."
      ]
    },
    {
      "metadata": {
        "id": "P544hbdXkPJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "credit_df = pd.read_csv('unit2_resources/german_credit_data.csv')\n",
        "# Remove unneeded columns from data.\n",
        "credit_df = credit_df.drop('Unnamed: 0', 1).drop('Saving accounts', 1).drop('Checking account', 1).drop('Credit amount', 1).drop('Duration', 1).drop('Age', 1)\n",
        "credit_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CT6Z8F9roSQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that each individual has some features associated with them (sex, job, housing purpose), along with a groundtruth risk values. While this dataset isn't difficult to interpret for a human, it is not well-suited for input into a simple machine learning model yet. Why? \n",
        "\n",
        "1) Our logistic regression model makes predictions on numbers, not text. Given (male, 2, own, radio/TV), a logistic regression model is hard-pressed to apply a dot-product to text. \n",
        "\n",
        "2) Even for numerical features (e.g., \"Job\") it is often more useful to split the feature up into a one-hot encoding, which is a series of 0's with one 1 in a position indicating the value of a feature. For example, since \"Job\" takes on 6 values, if we want to indicate that an individual has the second of the 6 jobs, we encode this as [0, 1, 0, 0, 0, 0] (or a vector with all 0's except a 1 in the second position). At a high level, this allows our model to separate out the effects of different job types better. You can find a more detailed explanation of one-hot-encoding and why it is useful [here](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f). \n",
        "\n",
        "We perform the necessary data processing steps for you below."
      ]
    },
    {
      "metadata": {
        "id": "AYAvdJ9HkPJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode_dataset(credit_df):\n",
        "    credit_df = credit_df.replace({'Sex': {'male': 0, 'female': 1}})\n",
        "    credit_df = credit_df.replace({'Housing': {'own': 0, 'rent': 1, 'free': 2}})\n",
        "    credit_df = credit_df.replace({'Purpose': {'car': 0, \n",
        "               'furniture/equipment': 1, 'radio/TV': 2, \n",
        "               'domestic appliances': 3, 'repairs': 4, 'education': 5, \n",
        "               'business': 6, 'vacation/others': 7}})\n",
        "    credit_df = credit_df.replace({'Risk': {'good': 1, 'bad': 0}})\n",
        "    enc = OneHotEncoder(categories='auto')\n",
        "    enc.fit(credit_df.values)\n",
        "    dataset = enc.transform(credit_df.values).toarray()\n",
        "    \n",
        "    # List of binary columns in the final data, where the last column is the\n",
        "    # risk to be predicted.\n",
        "    columns = ['female', 'job:1', 'job:2', 'job:3', 'job:4', 'job:5', 'job:6', \n",
        "               'housing:own', 'housing:rent', 'housing:free', \n",
        "               'purpose:car', 'purpose:furniture/equipment', 'purpose:radio/TV', \n",
        "               'purpose:domestic appliances', 'purpose:repairs', \n",
        "               'purpose:education', 'purpose:business', \n",
        "               'purpose:vacation/others', 'risk:good']\n",
        "    \n",
        "    # Convert back to dataframe for easy viewing.\n",
        "    processed_credit_df = pd.DataFrame(dataset, columns=columns)\n",
        "    \n",
        "    X, y = dataset[:, :-1], dataset[:, -1]\n",
        "    \n",
        "    return shuffle(X, y, random_state=0), processed_credit_df\n",
        "\n",
        "(X, y), processed_credit_df = one_hot_encode_dataset(credit_df)\n",
        "\n",
        "X_train, X_dev, X_test = X[:800], X[800:900], X[900:]\n",
        "y_train, y_dev, y_test = y[:800], y[800:900], y[900:]\n",
        "\n",
        "print(\"Training data shape\", X_train.shape, y_train.shape)\n",
        "print(\"Dev data shape\", X_dev.shape, y_dev.shape)\n",
        "print(\"Test data shape\", X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tzFF9KRBXrsV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "processed_credit_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQW4ZD5BmLZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's figure out the class imbalance so we have a baseline to better understand our model's performance. Hint: you want to find the mean value in *y_train*."
      ]
    },
    {
      "metadata": {
        "id": "gmPEOriYEHqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "### END CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pnhNtFfl31U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "0.70375"
      ]
    },
    {
      "metadata": {
        "id": "PIJWdIRZi9zh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fill in our familiar logistic regression helpers below. These are almost the same as in this week's exercises, but since there are no word vectors, we use the input *x* directly as a vector, rather than retrieving the word vector for a word."
      ]
    },
    {
      "metadata": {
        "id": "fqsjWCyh4iXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0 / (1 + np.exp(-z))\n",
        "  \n",
        "def compute_logistic_regression(x, weights, bias):\n",
        "  ### YOUR CODE HERE ###\n",
        "  return None\n",
        "  ### END CODE ###\n",
        "  \n",
        "def get_loss(y, y_hat):\n",
        "  ### YOUR CODE HERE ###\n",
        "  return None\n",
        "  ### END CODE ###\n",
        "  \n",
        "def get_weight_gradient(y, y_hat, x):\n",
        "  ### YOUR CODE HERE ###\n",
        "  return None\n",
        "  ### END CODE ###\n",
        "  \n",
        "def get_bias_gradient(y, y_hat, x):\n",
        "  ### YOUR CODE HERE ###\n",
        "  return None\n",
        "  ### END CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fi2S1jrpnKy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also have our handy *evaluate_model* function, which is unchanged from before. Make sure you still understand it!"
      ]
    },
    {
      "metadata": {
        "id": "P4DOS4wUX_3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_model(eval_data, weights, bias):\n",
        "    num_examples = len(eval_data)\n",
        "    total_correct = 0.0\n",
        "    true_positives = 0.0\n",
        "    false_positives = 0.0\n",
        "    false_negatives = 0.0\n",
        "    for i in range(num_examples):\n",
        "        x, y = eval_data[i]\n",
        "        pred = compute_logistic_regression(x, weights, bias)\n",
        "        \n",
        "        total_correct += 1 if (pred > .5 and y == 1 or pred <= .5 and y == 0) else 0\n",
        "        true_positives += 1 if pred > .5 and y == 1 else 0\n",
        "        false_positives += 1 if pred > .5 and y == 0 else 0\n",
        "        false_negatives += 1 if pred <= .5 and y == 1 else 0\n",
        "    print(\"Evaluation accuracy: \", total_correct / num_examples)\n",
        "    print(\"Precision: \", true_positives / (true_positives + false_positives))\n",
        "    print(\"Recall: \", true_positives / (true_positives + false_negatives))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icBvhBCtnSAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fill in *fit_logistic_regression* below. This will be similar to code you've written before, but we will also be evaluating on our dev dataset every 10 epochs (iterations through the training data). Note that *weights* should have dimensionality 18, since this is the size of each input vector."
      ]
    },
    {
      "metadata": {
        "id": "Gn16IHMd8j87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit_logistic_regression(training_data, dev_data, NUM_EPOCHS=50, LEARNING_RATE=0.0005):\n",
        "    np.random.seed(42)\n",
        "    # YOUR CODE HERE - initialize weights and bias\n",
        "\n",
        "    # END CODE\n",
        "    \n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        loss = 0\n",
        "        for example in training_data:\n",
        "            x, y = example\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            # END CODE\n",
        "        if epoch % 10 == 0:\n",
        "            print(\"Epoch %d, loss = %f\" % (epoch, loss))   \n",
        "            print(\"Evaluating model on dev data...\")\n",
        "            ### YOUR CODE HERE ###\n",
        "\n",
        "            ### END CODE ###\n",
        "    return weights, bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TRvtFGzRm4OX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then call our new fitting function to train while evaluating on dev data."
      ]
    },
    {
      "metadata": {
        "id": "FIYmD-QO9IM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_data = list(zip(X_train, y_train))\n",
        "dev_data = list(zip(X_dev, y_dev))\n",
        "weights, bias = fit_logistic_regression(training_data, dev_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpxaKQSdmwMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** First few lines of expected output:**\n",
        "\n",
        "Epoch 0, loss = 600.347192\n",
        "\n",
        "Evaluating model on dev data...\n",
        "\n",
        "Evaluation accuracy:  0.67\n",
        "\n",
        "Precision:  0.7065217391304348\n",
        "\n",
        "Recall:  0.9154929577464789\n",
        "\n",
        "** Last few lines of expected output:**\n",
        "\n",
        "Epoch 40, loss = 231.450579\n",
        "\n",
        "Evaluating model on dev data...\n",
        "\n",
        "Evaluation accuracy:  0.91\n",
        "\n",
        "Precision:  0.9305555555555556\n",
        "\n",
        "Recall:  0.9436619718309859\n",
        "\n",
        "\n",
        "\n",
        "Below, we evaluate our trained model on test data. This is where we see how we did on unseen data, i a real-world setting!"
      ]
    },
    {
      "metadata": {
        "id": "rBWXcxCMDcjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = list(zip(X_test, y_test))\n",
        "evaluate_model(test_data, weights, bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSt1m6TqDbCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**\n",
        "\n",
        "Evaluation accuracy:  0.91\n",
        "\n",
        "Precision:  0.9253731343283582\n",
        "\n",
        "Recall:  0.9393939393939394\n"
      ]
    },
    {
      "metadata": {
        "id": "TBA3J-hVyFH1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that we're doing well on both dev and test data! While this is a small toy dataset, our experiments suggest that even simple machine learning models are capable of making predictions on humans that can have long lasting effects (whether I get a loan can impact my financial situation years down the road). In coming weeks (particularly weeks 5 and 6), we will learn about the implications of potentially biased models that make predictions on humans.\n",
        "\n",
        "Let's now investigate how important the \"gender\" feature is to the model in making the decision. First, we will grab all females from the test set:"
      ]
    },
    {
      "metadata": {
        "id": "2q5SKvt6kPKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_female = X_test[X_test[:, 0] == 1]\n",
        "print(\"There are %i females in the test set.\" % len(X_test_female))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spl8cw1DwZh5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**\n",
        "\n",
        "There are 68 females in the test set.\n"
      ]
    },
    {
      "metadata": {
        "id": "QIWLJz6DyJMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's see how many of them had loans approved:"
      ]
    },
    {
      "metadata": {
        "id": "re1zaEfkkPKG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = [compute_logistic_regression(x, weights, bias) for x in X_test_female]\n",
        "total_good = sum(1 if result > .5 else 0 for result in results)\n",
        "print(\"%i females had loans approved.\" % total_good)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6GoxxhW5wtZ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**\n",
        "\n",
        "44 females had loans approved."
      ]
    },
    {
      "metadata": {
        "id": "SlfLbSpYyOfT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, let's change the gender feature to not female. We will input the same exact features into the model, except with gender changed from female to male. Hopefully, the number of loans approved will stay the same!"
      ]
    },
    {
      "metadata": {
        "id": "9bKanxPjkPKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_all_male = X_test_female.copy()\n",
        "X_test_all_male[:, 0] = 0\n",
        "\n",
        "results = [compute_logistic_regression(x, weights, bias) for x in X_test_all_male]\n",
        "total_good = sum(1 if result > .5 else 0 for result in results)\n",
        "print(\"%i females with gender changed had loans approved.\" % total_good)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNl3kqrUw5gm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**\n",
        "\n",
        "39 females with gender changed had loans approved.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Xy6B_GJdyRVR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Oh no! Seems like the number of loans approved have decreased! In other words, even with everything else the same, only a different gender causes certain people (such as males and non-binary people) to be disadvantaged by our algorithm. Although the difference is minimal, remember that the test set size is just 100. This means that 5% of people were \"misclassified\" based off of a protected class--that's huge!\n",
        "\n",
        "This is why it's important to be sure to debias your dataset and do a thorough hyperparameter sweep. See if you can change the hyperparamters to get a more fair model!"
      ]
    },
    {
      "metadata": {
        "id": "6a87pA7U2lI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}